<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>How to Train Vision Transformer Training on Small Datasets | Daekyung Kim</title> <meta name="author" content="Daekyung Kim"/> <meta name="description" content="Proposed method serves as an effective weights initialization to successfully train ViTs from scratch, thus eliminating the need for large-scale pre-training."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ“Ÿ</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://dkdkkim.github.io/blog/2022/vit-on-small/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://dkdkkim.github.io/"><span class="font-weight-bold">Daekyung</span> Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">How to Train Vision Transformer Training on Small Datasets</h1> <p class="post-meta">October 21, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> Â  Â· Â  <a href="/blog/tag/review"> <i class="fas fa-hashtag fa-sm"></i> review</a> Â  Â  Â· Â  <a href="/blog/category/paper-review"> <i class="fas fa-tag fa-sm"></i> paper-review</a> Â  </p> </header> <article class="post-content"> <p>ì•ì„œ ì´ì•¼ê¸°í–ˆë“¯ì´ Image recognitionì˜ ì—¬ëŸ¬ê°€ì§€ ë¶„ì•¼ì—ì„œ Vision TransformerëŠ” ë§ì€ ì„±ê³¼ë¥¼ ì´ë£¨ì–´ëƒˆë‹¤. í•˜ì§€ë§Œ ì—¬ì „íˆ ê°€ì§€ê³  ìˆëŠ” í•œê³„ì ì€ large-scaleì˜ ë°ì´í„°ì…‹ì— í•œì •ì ìœ¼ë¡œ íš¨ê³¼ê°€ ìˆë‹¤ëŠ” ì ì´ë‹¤. ë”°ë¼ì„œ large-scaleì˜ ë°ì´í„°ë¥¼ í™•ë³´í•˜ê¸° í˜ë“  ë¶„ì•¼ì—ì„œëŠ” ì´ëŸ° ë¬¸ì œë¡œ ë‹¤ì–‘í•œ ViT ëª¨ë¸ì´ ì¡´ì¬í•¨ì—ë„ ë¶ˆêµ¬í•˜ ì ìš©í•˜ëŠ”ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤. ì´ë²ˆì— ë¦¬ë·°í•˜ëŠ” ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ° ë‹¨ì ì„ ë³´ì™„í•˜ê³ ì í•œê°€ì§€ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.</p> <hr> <h2 id="problem"><strong>Problem</strong></h2> <p>ViTê°€ small-scale datasetì„ í•™ìŠµí•˜ëŠ” ë°ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ì´ìœ ëŠ” ViT ì•Œê³ ë¦¬ì¦˜ íŠ¹ì„±ìƒ locality, inductive bias, hierarchical sturucture ê°€ ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë¹„ìŠ·í•œ ì´ìœ ë¡œ ViTëŠ” transfer learningì„ í•˜ê¸° ìœ„í•´ì„œ large-scale datasetì— pretrainingì„ í•„ìš”ë¡œ í•œë‹¤. ê²°ê³¼ì ìœ¼ë¡œ large-scale datasetì´ ì—†ëŠ” ê²½ìš°ì—ëŠ” ViTì˜ ì„±ëŠ¥ì€ ì œí•œëœë‹¤.</p> <hr> <h2 id="approach"><strong>Approach</strong></h2> <p>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” small datasetì—ì„œ low-resolution viewë¥¼ í™œìš©í•´ì„œ sef-supervised learningì„ í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤. ì´ ë°©ë²•ì€ large datasetì—ì„œì˜ pretraining ì—†ì´ ViTë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” íš¨ê³¼ì ì¸ initial weightsë¥¼ ì œê³µí•œë‹¤. ì´ë•Œ self-supervised learning í•˜ëŠ” ë°©ì‹ì€ <a href="https://arxiv.org/pdf/2104.14294.pdf" target="_blank" rel="noopener noreferrer">DINO</a>ì—ì„œ ì œì•ˆí•œ ë°©ì‹ê³¼ ì•„ì£¼ ìœ ì‚¬í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ DINOë¥¼ ë¨¼ì € ìˆ™ì§€í•œë‹¤ë©´ Proposed methodëŠ” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤.</p> <div> <center><img src="../../../assets/img/small01.gif" alt="small_dino" width="60%" height="60%"></center> </div> <div class="caption"> <center>Concept of DINO</center> </div> <hr> <h2 id="method"><strong>Method</strong></h2> <p>ì•ì„œ ë§í–ˆë“¯ì´ ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ì€ Self-supervised learningì„ í†µí•´ íš¨ê³¼ì ì¸ initial weightsë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì€ í¬ê²Œ Self-supervised learning í•˜ëŠ” ê³¼ì •ê³¼ ì´ë•Œì˜ weight ê°’ì„ í™œìš©í•˜ì—¬ supervised learning í•˜ëŠ” ë‘ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ ë³¼ ìˆ˜ ìˆë‹¤.</p> <h3 id="self-supervised-view-prediction-as-weight-initialization-scheme">Self-supervised View Prediction as Weight Initialization Scheme</h3> <p>Self-supervised learning ê³¼ì •ì„ ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. DINOì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë™ì¼í•œ ë‘ê°œì˜ ëª¨ë¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©° ê°ê° student modelê³¼ teacher model ì´ë¼ê³  í•œë‹¤.</p> <div> <center><img src="../../../assets/img/small02.png" alt="small_self" width="50%" height="50%"></center> </div> <div class="caption"> <center>Self-supervised View Prediction as Weight Initialization Scheme</center> </div> <p>í•™ìŠµì„ ìœ„í•´ Input image ì—ì„œ ì¼ì¢…ì˜ augmentationì„ í†µí•´ local viewì™€ global view ë‘ê°€ì§€ì˜ imageë¥¼ ìƒì„±í•œë‹¤. ë‘ê°€ì§€ì˜ ì°¨ì´ì ì€ local view \(x_l\)ëŠ” ì›ë³¸ì´ë¯¸ì§€ì˜ 20~50%ì˜ í¬ê¸°ì˜ crop ëœ ì´ë¯¸ì§€ì´ê³  global view \(x_g\)ëŠ” ì›ë³¸ì´ë¯¸ì§€ì˜ 50%í¬ê¸° ì´ìƒì¸ ì´ë¯¸ì§€ì´ë¼ëŠ” ì ì´ë‹¤. \(x_l\)ê³¼ \(x_g\)ì˜ í¬ê¸°ì˜ ë¹„ìœ¨ì€ 1:4ê°€ ë˜ë„ë¡ í•œë‹¤. ëª¨ë“  ì´ë¯¸ì§€ëŠ” color jittering, gray scaling, solarization, random hrizontal flip and gausian blurë¥¼ í¬í•¨í•œ standar augmentationì„ ì ìš©í•œë‹¤.</p> <p>Student model \(F_s\)ì—ëŠ” ëª¨ë“  imageê°€ DPE(Dynamic Position Embedding)ë¥¼ í†µí•´ position embeding ì²˜ë¦¬ê°€ ëœ í›„ ì…ë ¥ëœë‹¤. ë°˜ë©´ì— Teacher model \(F_g\)ì—ëŠ” global view ë§Œ ì…ë ¥ë˜ê²Œ ëœë‹¤. ê°ê°ì˜ ëª¨ë¸ì€ ëª¨ë‘ ViTì´ê³  ViT ë’¤ì— MLP headë¥¼ í†µê³¼ í•˜ê²Œ ëœë‹¤. MLP headëŠ” 3ê°œì˜ linear layerë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , single layer ë³´ë‹¤ multi layerê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ê³  í•œë‹¤.</p> <p>ì…ë ¥ëœ ì´ë¯¸ì§€ì™€ ì‚¬ìš©ëœ ëª¨ë¸ì— ë”°ë¼ì„œ ê°ê° \(F_s(x_l)\), \(F_s(x_l)\), \(F_t(x_g)\) ì´ ìƒì„±ëœë‹¤. ì˜ˆë¥¼ ë“¤ë©´, \(F_s(x_l)\) ì˜ ê²½ìš°ëŠ” local view ê°€ student modelì„ í†µí•´ ìƒì„±ëœ ì¶œë ¥ê°’ì´ë‹¤. student modelì€ ì´ ì¶œë ¥ê°’ë“¤ì„ í™œìš©í•˜ì—¬ ì•„ë˜ì˜ cost functionì„ í†µí•´ì„œ update ëœë‹¤.</p> \[\mathfrak{L}=-\widetilde{F}_{g_t}\cdot \log(\widetilde{F}_{g_s})+\sum_{i=1}^{n}-\widetilde{F}_{g_t}\cdot \log(\widetilde{F}^{(i)}_{l_s})\] <p>teacher model \(F_t\)ëŠ” ì¼ë°˜ì ì¸ teacher-student í•™ìŠµì²˜ëŸ¼ ì•„ë˜ì˜ ìˆ˜ì‹ëŒ€ë¡œ ë‘ëª¨ë¸ì˜ weight \({\theta}_{s}\), \({\theta}_{t}\) ì˜ exponential moving averageë¥¼ ì´ìš©í•˜ì—¬ ì—…ë°ì´íŠ¸ ëœë‹¤.</p> \[{\theta}_{t} \leftarrow \lambda{\theta}_{t}+(1-\lambda{\theta}_{s})\] <h3 id="self-supervised-to-supervised-label-prediction">Self-supervised to Supervised Label Prediction</h3> <p>ì•ì„œ Self-supervised learningì„ í†µí•´ì„œ íšë“í•œ weight ê°’ì„ í™œìš©í•˜ì—¬ supervised learningdmf ì§„í–‰í•˜ê²Œ ëœë‹¤. ë‘ê°€ì§€ ëª¨ë¸ì¤‘ teacher ëª¨ë¸ì˜ weightë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ í•˜ì—¬ ëª©í‘œê°€ ë˜ëŠ” supervised learningì„ ì§„í–‰í•˜ë©° ì´ ê³¼ì •ì€ ì¼ë°˜ì ì¸ ViTì˜ í•™ìŠµê³¼ì •ê³¼ ìœ ì‚¬í•˜ê²Œ CE lossë¡œ í•™ìŠµì„ ì§„í–‰í•œë‹¤.</p> <div> <center><img src="../../../assets/img/small03.png" alt="small_supervised" width="50%" height="50%"></center> </div> <div class="caption"> <center>Self-supervised to Supervised Label Prediction</center> </div> <hr> <h2 id="experimental-result"><strong>Experimental result</strong></h2> <p>CIFARë‚˜ Tiny-ImageNet ê³¼ ê°™ì€ small-scale datasetì€ 32 ë˜ëŠ” 64 ì™€ ê°™ì´ ë‚®ì€ í•´ìƒë„ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ë”°ë¼ì„œ ì‹¤í—˜ì— ì‚¬ìš©ë˜ëŠ” patch sizeì™€ ì´ì— ë”°ë¥¸ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•˜ì˜€ë‹¤ê³  í•œë‹¤.</p> <div> <center><img src="../../../assets/img/small04.png" alt="small_exp_set" width="60%" height="60%"></center> </div> <div class="caption"> <center>Details of ViT encoders used in our proposed training approach</center> </div> <p>ì‹¤í—˜ì—ëŠ” ì•„ë˜ì™€ ê°™ì´ 7ê°œì˜ small-scale datasetì´ ì‚¬ìš©ë˜ì—ˆë‹¤.</p> <div> <center><img src="../../../assets/img/small05.png" alt="small_datasets" width="60%" height="60%"></center> </div> <div class="caption"> <center>Details of datasets</center> </div> <p>ì‹¤í—˜ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ ëŒ€ë¶€ë¶„ì˜ ì‹¤í—˜ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. Comparison modelë¡œëŠ” Dense relative localization taskë¥¼ í™œìš©í•œ <a href="https://arxiv.org/pdf/2106.03746.pdf" target="_blank" rel="noopener noreferrer">ViT-Drloc</a>ê³¼ Shifted Patch Tokenizationê³¼ Locality Self-Attentionì„ í™œìš©í•œ <a href="https://arxiv.org/pdf/2112.13492.pdf" target="_blank" rel="noopener noreferrer">SL-ViT</a>ê°€ ìˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.</p> <div> <center><img src="../../../assets/img/small06.png" alt="small_exp" width="60%" height="60%"></center> </div> <div class="caption"> <center>Comparison Performance</center> </div> <p>íŠ¹íˆ salient objectì— ëŒ€í•´ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ë° feature mapì„ ì‹œê°í™”í•œ ì•„ë˜ figureë¥¼ ë³´ë©´ ë³¸ ì—°êµ¬ì—ì„œ ì œì•ˆí•œ ëª¨ë¸ì—ì„œ ì£¼ë³€ë¶€ëŒ€ë¹„ salient objectê°€ ë” ì˜ í™œì„±í™” ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.</p> <div> <center><img src="../../../assets/img/small07.png" alt="small_salient" width="60%" height="60%"></center> </div> <div class="caption"> <center>Comparison with salient objects</center> </div> <p>ë” ì ì€ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹¤í—˜ê²°ê³¼ë„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° CIFAR10, CIFAR100ì˜ 25%,50%,75%ì˜ ë°ì´í„°ë¡œ í•™ìŠµí•œ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì•„ë„ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.</p> <div> <center><img src="../../../assets/img/small08.png" alt="small_part" width="60%" height="60%"></center> </div> <div class="caption"> <center>Training with part of small dataset</center> </div> <hr> <h2 id="comments"><strong>Comments</strong></h2> <p>ViTê°€ ì²˜ìŒìœ¼ë¡œ ì œì•ˆëœì§€ ì˜¤ëœ ì‹œê°„ì´ ì§€ë‚¬ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì§€ê¸ˆê¹Œì§€ë„ ì´ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆë‹¤. ë‹¤ì–‘í•œ image recognition taskë“¤ì—ì„œ SOTA modelì˜ ìë¦¬ëŠ” ViTê°€ ì°¨ì§€ í•œì§€ ì˜¤ë˜ë˜ì—ˆì§€ë§Œ, ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šê³  ìˆëŠ” ëª‡ê°€ì§€ í•œê³„ì ë„ ìˆì—ˆë‹¤. ê·¸ ì¤‘ í•˜ë‚˜ê°€ small datasetì— ëŒ€í•œ ë¬¸ì œì˜€ê³  ì•ì„œ ë¦¬ë·°í•œ ë…¼ë¬¸ë¿ë§Œ ì•„ë‹ˆë¼ ì—¬ëŸ¬ê°€ì§€ ì—°êµ¬ì—ì„œ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì œì•ˆí•˜ê³  ìˆë‹¤. ê°œì¸ì ì¸ ìƒê°ìœ¼ë¡œëŠ” ì•„ì§ë„ ì™„ì „íˆ í•´ê²°ëœ ê²ƒ ì²˜ëŸ¼ë³´ì´ì§€ëŠ” ì•Šì§€ë§Œ, ê·¸ ë‹¨ì ì´ ì‹œê°„ì´ ì§€ë‚˜ê³  ì—°êµ¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ì„œ ì¡°ê¸ˆì”© ë³´ì™„ë˜ê³  ìˆê¸° ë•Œë¬¸ì— ë˜ ì–´ë–¤ í˜ì‹ ì ì¸ ì•Œê³ ë¦¬ì¦˜ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ëŠ” ì•ìœ¼ë¡œë„ í•œë™ì•ˆì€ ViTê°€ ëŒ€ì„¸ì¼ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.</p> <hr> <h2 id="reference">Reference</h2> <ul> <li><a href="https://arxiv.org/pdf/2104.14294.pdf" target="_blank" rel="noopener noreferrer">Caron, Mathilde, et al. â€œEmerging properties in self-supervised vision transformers.â€ Proceedings of the IEEE/CVF international conference on computer vision. 2021.</a></li> <li><a href="https://arxiv.org/pdf/2210.07240.pdf" target="_blank" rel="noopener noreferrer">Gani, Hanan, Muzammal Naseer, and Mohammad Yaqub. â€œHow to Train Vision Transformer on Small-scale Datasets?.â€ arXiv preprint arXiv:2210.07240 (2022).</a></li> <li><a href="https://arxiv.org/pdf/2112.13492.pdf" target="_blank" rel="noopener noreferrer">Lee, Seung Hoon, Seunghyun Lee, and Byung Cheol Song. â€œVision transformer for small-size datasets.â€ arXiv preprint arXiv:2112.13492 (2021).</a></li> <li><a href="https://arxiv.org/pdf/2106.03746.pdf" target="_blank" rel="noopener noreferrer">Liu, Yahui, et al. â€œEfficient training of visual transformers with small datasets.â€ Advances in Neural Information Processing Systems 34 (2021): 23818-23830.</a></li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Daekyung Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: April 15, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>