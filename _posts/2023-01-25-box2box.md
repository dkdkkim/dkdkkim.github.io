---
layout: post
title: Box2Mask, Box-supervised Instance Segmentation via Level-set Evolution
date:   2023-01-25 00:00:00
description: box-supervised instance segmentation takes advantage of the simple box annotation rather than the pixel-wise mask labels, which has recently attracted a lot of research attentions.
tags: review
categories: paper-review
---

Segmentation 기술은 지속적으로 발전되어 현재의 SOTA 모델의 성능은 상당히 높은 수준에 이르렀으며, 실제 필드에서도 여러가지 적용사례를 보여주고 있다. 하지만 Segmentation task의 한계는 Labeling cost 라고 할 수 있다. Segmentation을 하기 위한 Ground truth mask 는 pixel 단위로 annotation 을 해야하기 때문에 Classification 이나 detection 등에 비해서 많은 Human resource 를 필요로 한다.
이런 한계를 극복하고자 제안한 접근중에 하나가 Box-supervised Instance Segmentation 이다. 직관적으로 알 수 있듯이 Detection 에 사용되는 Bounding Box를 활용해 Instance Segmentation의 기능을 하도록 하는 것으로 일종의 Weakly supervised learning 이라고 할 수 있다.
다른 Task 에 비해서 비교적 많은 연구가 이루어 지지는 않았지만, 흥미로운 주제이기에 현재 기준으로 SOTA model을 달성한 연구에 대해서 알아보고자 한다.

---

## **Problem**
이미 앞서 설명했지만, 대부분의 instance segmentation 접근법들은 supervised learning 방식으로 이루어지고 있으며, 이에 따라서 pixel level로 mask annotation을 하는데에 상당히 큰 cost를 필요로 한다.
box-supervised instance segmentation은 상대적으로 단순한 box annotation 만 있으면 되기 때문에 조금씩 연구가 이루어 지고 있다.
Paper with code 에서 box-supervised instance segmentation 의 Ranking을 확인해보면 아래와 같이 2019년 이후로 지속적으로 연구가 이루어 지고 있음을 알 수 있다.

<div>
    <center><img src="../../../assets/img/box01.png" alt="box_rank" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Box-supervised Instance Segmentation on COCO test-dev</center>
</div>

---

## **Approach**
본 논문에서는 [SOLOV2](https://proceedings.neurips.cc/paper_files/paper/2020/file/cd3afef9b8b89558cd56638c3631868a-Paper.pdf) 와 Level Set Segmentation을 활용한 Box-instance segmentation을 제안한다. SOLOV2는 full instance mask annotations를 이용하여 Segmentation 하는 [SOLO](https://arxiv.org/pdf/1912.04488.pdf)의 개선 모델이다. Level Set Segmentation은 전통적인 Computer vision 에서 이전부터 사용되던 방법중의 하나이다. 전체적인 Architecture는 아래와 같다.

<div>
    <center><img src="../../../assets/img/box02.png" alt="box_arch" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Architecture of BOX2SEG</center>
</div>

---

## **Method**
본 논문에서 제안하는 방법은 크게 SOLOV2와 Level Set Evolution 으로 구성되어 있는 것을 알 수 있다. 따라서 이 두가지 방법에 대한 이해가 선행되어야 한다.

### SOLO
SOLOV2 는 SOLO 의 개선된 버전이기 때문에 SOLO를 먼저 설명하려한다. SOLO 는 기존에 접근과는 다른 방식으로 Instance segmentation을 수행한다. 먼저 Image 를 $$ S \times S $$  로 분할하여 접근하며 FPN 의 모든 Feature map 에 대해서 Category branch와 Mask branch가 적용된다. 아래 그림이 SOLO에서 제안하는 방식이다.

<div>
    <center><img src="../../../assets/img/box03.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Concept of SOLO</center>
</div>

Category Branch 의 output 은 $$ S \times S \times C $$ 의 shape를 가지고 있으며 $$ S \times S $$ 그리드의 Class를 나타낸다.

Mask Branch 의 output 은 $$ H \times W \times S^2 $$ 으로 $$ S^2 $$ 개의 그리드에 해당하는 segmentation mask 이다. Mask Branch 에서는 각각의 mask 가 그리드에 match 되도록 하기 위하여 x, y 좌표를 normalize 한 값을 concat 하는 CoordConv 를 사용하였다.

결과적으로 두 브랜치의 output을 활용하면 각각의 그리드에 해당하는 Segmentation mask와 Category 를 알 수 있게 된다.

### SOLO V2
하지만 SOLO 에 대한 방법을 보다보면 걱정이 되는 부분이 생길 수 밖에 없을 것이다. 바로 SOLO의 방법은 높은 Computational Cost를 필요로 한다는 점이다. 이런 단점을 극복한 방법이 SOLO V2 이다.
SOLO 에서 사용되었던 Category branch와 Mask branch 대신에 kernel branch와 feature branch 가 새롭게 제안되었다.

<div>
    <center><img src="../../../assets/img/box04.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Concept of SOLO V2</center>
</div>

feauter branch 의 output $$ F $$ 는 $$ H \times W \times E $$ 의 shape를 가진다. 이때 $$ E $$ 는 N of channel로 보면 된다.

kernel branch 가 key idea 라고 할 수 있는데, 여기서는 $$ F $$ 에 Convolution 연산을 할 filter 의 weight를 학습하는 역할을 하게 된다. Output $$ G $$ 는 $$ S \times S \times D $$ 를 이루게 되는데 이는 $$ S^2 $$ 개의 filter weight를 나타내며 각각의 그리드에 해당한다. 예를들어 $$ 3 \times 3 $$ 의 conv filter를 적용하려고 한다면 $$ D = E \times (3 \times 3) $$ 이된다.

결과적으로 $$ F $$ 와 $$ G $$ 가 convolution 연산을 하게 되면 SOLO 와 마찬가지로 $$ H \times W \times S^2 $$ 의 segmentation map이 출력된다. 앞서 설명한 방법으로 SOLO V2 는 SOLO 보다 효율적이면서 더 높은 성능을 보였다.


### Level-set segmentation
Level-set segmentation은 level-set function을 활용하여 image 를 segmentation 하는 방식을 말한다. Level-set function을 $$ \phi (x) $$ 라고 가정하면 $$ \{x \mid \phi (x) = c \} $$를 활용하여 아래와 같이 segmentation을 수행할 수 있다.

<div>
    <center><img src="../../../assets/img/box05.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Level set segmentation(wikipedia)</center>
</div>

Level-set segmentaton의 좋은 결과를 내기 위해서는 최적의 level-set function을 찾아야 하는데 이때 사용하는 방식이 Energy function을 활용하는 방식이다. Level-set function 에 대한 Energy function을 정의하여 Energy가 최소화 하도록 Level-set function을 반복하여 업데이트 하여 최적화 하는 방식이다.

<div>
    <center><img src="../../../assets/img/box06.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center></center>
</div>

위와 같은 식으로 업데이트 되는데 이때 initial level-set function과 Energy function을 어떤 방식으로 정의하느냐에 따라서 그 결과는 달라진다.
이 Energy function을 정의 하는 방법중의 하나가 [Active contours without edges]() 이다.

<div>
    <center><img src="../../../assets/img/box07.png" alt="small_solo" width="100%" height="60%"></center>
</div>
<div class="caption">
     <center></center>
</div>

위의 식이 [Active contours without edges](https://www.lpi.tel.uva.es/muitic/pim/docus/ActiveContoursWithoutEdges.pdf)에서 제안한 Energy function 이다. 개념적으로 간단히 설명하자면 4개의 term 으로 이루어져 있고 각각 contour의 length, $$ \phi \ge 0 $$ area의 넗이, inside area, outside area를 의미한다. $$ c1, c2 $$ 는 각각 inside 와 outside의 intensity average를 이다.

### BOX2SEG
본 연구에서 제안한 BOX2SEG 에서는 SOLO V2를 통해서 나온 output 을 initial level-set function $$ {\phi}_0 $$ 로 가정하고 SOLO V2의 feature branch의 output을 Conv layer를 통과시킨 $$ I_{feat} $$, 원본 이미지에서 추출된 feature map $$ I_{img} $$ 를 활용하여 Level-set evolution을 수행한다.

<div>
    <center><img src="../../../assets/img/box08.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Level set evolution</center>
</div>

Level set evolution 에서는 아래와 같은 식으로 Energy function을 정의하는데 Active contours without edges 와 유사한 방식임을 알 수 있다.

<div>
    <center><img src="../../../assets/img/box09.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center></center>
</div>

input feature map $$ I_f $$, $$ I_u $$ 를 weighted summation 하여 아래와 같이 최종적인 energy function이 정의되고, 앞서 설명한 방식대로 level-set function을 최적화 한다.

<div>
    <center><img src="../../../assets/img/box10_new.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center></center>
</div>

모델의 학습에 쓰이는 loss function은 $$ wL_{cate} + L_{inst} $$ 로 category classification loss 와 instance segmentation loss로 이루어져 있으며 $$ L_{cate} $$ 는 일반적인 cross entropy loss를 사용하고 $$ L_{inst} $$ 는 앞서 설명한 energy function $$ F(x) $$ 와 $$ F(\phi_0)_{box} $$ 로 이루어져 있는데 $$ F(\phi_0)_{box} $$ 는 아래 식에서 알 수 있듯이 predicted mask 와 box label을 각 axis 에 projection 했을때 차이를 나타낸다.

<div>
    <center><img src="../../../assets/img/box11.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center></center>
</div>


SOLO와 level-set function 까지 함께 설명하자니 내용이 복잡해졌는데, 여기까지가 BOX2SEG의 Method 에 대한 설명이다.

---

## **Experimental result**
BOX2SEG의 성능을 검증하기 위하여 Pascal VOC, COCO, iSAID, LiTS(Liver tumor), ICDAR2019 ReCTS 의 다양한 데이터 셋에서 실험을 진행하였다. 
아래는 COCO dataset에서의 결과인데, box-supervised 에서 가장 좋은 성능을 보이는 것을 알 수 있다. 게다가 mask-supervised 와 비교했을 때에도 대부분의 모델보다 좋은 성능을 보이는 것을 알 수 있다.

<div>
    <center><img src="../../../assets/img/box12.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Experimental result on COCO test-dev</center>
</div>

아래 정성적인 결과를 보면 general image 뿐만 아니라 medical image, scene text 등에도 꽤나 효과적인 것을 확인할 수 있다.

<div>
    <center><img src="../../../assets/img/box13.png" alt="small_solo" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Qualitative result of BOX2SEG</center>
</div>

---

## **Comments**
최근 효과적인 Large model들에 대한 연구들이 좋은 성과를 내기 시작하고 있다. 성공한 연구들을 보면 NLP나 Image classification 처럼 충분한 데이터를 갖춘 분야들임을 알 수 있다. Segmentation이라는 task는 이런 데이터 관점에서 매우 불리한 Task이고 다른 task 처럼 방대한 데이터셋은 언제 구축될 수 있을 지 모른다. 이런 관점에서 box-supervised segmentation과 같은 접근은 적어도 한동안은 연구되어야 할 분야라는 생각이 든다.

---

## Reference
- [Li, Wentong, et al. "Box2Mask: Box-supervised Instance Segmentation via Level-set Evolution." arXiv preprint arXiv:2212.01579 (2022).](https://arxiv.org/pdf/2212.01579v1.pdf)
- [Wang, Xinlong, et al. "Solo: Segmenting objects by locations." Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XVIII 16. Springer International Publishing, 2020.](https://arxiv.org/abs/1912.04488)
- [Wang, Xinlong, et al. "Solov2: Dynamic and fast instance segmentation." Advances in Neural information processing systems 33 (2020): 17721-17732.](https://proceedings.neurips.cc/paper_files/paper/2020/file/cd3afef9b8b89558cd56638c3631868a-Paper.pdf)
- [Chan, Tony F., and Luminita A. Vese. "Active Contours Without Edges." IEEE TRANSACTIONS ON IMAGE PROCESSING 10.2 (2001).](https://www.lpi.tel.uva.es/muitic/pim/docus/ActiveContoursWithoutEdges.pdf)
- [Tian, Zhi, et al. "Boxinst: High-performance instance segmentation with box annotations." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.](https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.pdf)
- [Level set function, wikipedia](https://en.wikipedia.org/wiki/Level-set_method)