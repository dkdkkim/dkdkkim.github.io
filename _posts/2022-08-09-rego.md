---
layout: post
title: Recurrent Glimpse-based Decoder for Detection with Transformer
date:   2022-08-09 00:00:00
description: the Region-of-Interest (RoI) based detection refinement can easily help mitigate the difficulty of training for DETR methods
tags: review
categories: paper-review
---

최근 Image recognition의 여러가지 분야에서 Vision Transformer는 많은 성과를 이루어냈다. Object detection 분야에서도 그 트렌드는 다르지 않았는데 그 대표적인예가 [DETR(Detection with Transformer)](https://arxiv.org/abs/2005.12872) 라고 할 수 있다. 다만 Vision Transformer의 경우 CNN 에 비해서 상대적으로 많은 데이터로 오랫동안 트레이닝해야 한다는 한계점을 가지고 있다. 이런 단점을 극복하기 위해 여러가지 접근들이 있었는데 이번에 소개할 논문도 그런 접근들 중에 하나이다.

---

## **Problem**
앞에서 말했다시피 DETR의 효과는 여러 연구를 통해서 검증이 되었고 그 연구는 점점 늘어가고 있다. 하지만 DETR은 일정 수준이상의 검출성능을 학습하기까지 아주 오랜시간을 요구한다. MS COCO dataset의 경우를 예로 들자면, [Feature Pyramid Network(FPN)](https://arxiv.org/abs/1612.03144)의 경우에는 36 epoch 정도면 되는 성능까지 학습되는데에 **500 epoch** 정도가 소요된다. V100이라는 높은 성능의 GPU 8개를 사용해도 10일 이상이 걸리는 수준이기 때문에 실질적으로 모델을 학습하고 사용하는데에 어려움이 있을 수 밖에 없다.

---

## **Approach**
본 논문에서는 REcurrent Glimpse-based decOder(REGO)라는 모델을 제안하고 있다. 이 모델은 이전의 다른 접근들과는 다른게 RoI에 집중하여 detection을 refinement 할 경우 DETR의 학습의 어려움을 비교적 쉽게 개선한다. 이전의 접근들은 feature 단이나 embedding 부분들을 통해서 문제를 해결하고자하는 방법론들이 대부분이었다.
<div>
    <center><img src="../../../assets/img/rego01.png" alt="rego_approach" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Concept of REcurrent glimpse-based decoder (REGO)</center>
</div>

---

## **Method**
REGO model의 전체적인 workflow는 DETR의 출력물인 $$ O_{box} $$와 feature $$ H_{dec} $$을 입력으로 받아 $$N$$개의 step의 반복을 통해서 최종적인 prediction을 하게 되며, 각각의 step은 Glimpse-based Decoder로 구성되어있다.

<div>
    <center><img src="../../../assets/img/rego02.png" alt="rego_method" width="70%" height="70%"></center>
</div>
<div class="caption">
     <center>The overview of the REGO</center>
</div>

### Glimpse-based Decoder

DETR의 output 또는 이전 block의 출력값중 $$O_{box}(i-1)$$을 이용하여 해당영역에서 feature를 추출하게 된다. 이때에 box 값을 그대로 사용하는 것이 아니라 margin을 갖고 조금더 넓은 영역에서 feature를 추출하는데 Diagram에서 Enlarge라고 표시된 부분이다. 이때 enlarge 하는 비율을 나타내는 glimpse scale $$\alpha$$ 는 점점 감소하게 되는데 3step일 경우를 예로 들면 $$\alpha=3,2,1$$ 이된다.

<div>
    <center><img src="../../../assets/img/rego03.png" alt="rego_method" width="30%" height="30%"></center>
</div>
<div class="caption">
     <center>Enlarge step of Glimpse-based Decoder</center>
</div>

이렇게 해당 RoI에서 추출된 feature $$V(i)$$는 query 값이 되고 이전 block으로 부터의 feature $$Hec(i-1)$$ 은 Linear Projection으로 dimension 조정 후 key, value 값이 되어 Multi-head cross attention 후 $$H_{g}(i)$$ 가 된다. $$H_{g}(i)$$ 와 $$Hec(i-1)$$를 concatenation을 통해 하나의 feature로 만들고 MLP를 통해서 새로운 Detected Boxes $$O_{box}(i)$$, Classification Output $$O_{cls}(i)$$ 그리고 Decoding Output $$H_{dec}(i)$$ 를 출력하게 된다.

### Multi-stage Reccurent Processing
이런 glimpes-based Decoder를 $N$번 반복하여 ReGO model 이 완성되며 중간과정에서는 box와 feature 만 사용되지만 마지막 블럭에서는 classification 값까지 최종 예측값으로 사용된다. 본논문에서 일반적으로 step의 수 $N$은 3을 사용하였으며, 이는 실험적으로 선택된 것으로 보인다.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/rego04.png" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/rego05.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
     Hyper-parameter study of the number of stages in REGO and  the glimpse scale in REGO
</div>

---

## **Experimental result**
MS COCO validation split에서 35, 50 epoch에서의 결과를 아래와 같이 여러가지 existing Object Detection 모델들과 비교했으며, 관심을 가지고 보아야할 부분은 일반적인 DETR과 앞서 Training 문제를 개선한 [Deformable DETR](https://arxiv.org/abs/2010.04159) 과의 비교이다.

<div>
    <center><img src="../../../assets/img/rego06.png" alt="rego_method" width="60%" height="60%"></center>
</div>
<div class="caption">
     <center>Results of different detectors on the MS COCO val split</center>
</div>

표에서 보면 알 수 있듯이 DETR 은 물론이도 Deformable DETR 보다도 동일 epoch을 training 했을 때 높은 성능을 보임을 알 수 있다. 심지어 동일한 ResNet 50 backbone 기준으로 보았을 때에 REGO로 36 epoch을 training 했을 때 성능(44.8)이 Deformable DETR 의 성능(43.8) 보다 높은 것까지도 확인할 수 있다.

---

## **Limitations**
본 논문에서 저자도 언급했지만, REGO를 통해서 DETR의 학습 효율은 많이 개선되었지만 여전히 training 하는데에 수 일이 소요되기 때문에 앞으로도 개선의 여지는 남아있다고 볼 수 있다.
그리고 개인적으로는 본 논문에서 성능 검증에 사용된 지표는 validation split의 결과여서 test split에서의 성능의 검증이 필요하고, 50 epoch이상 training 하여 최종적으로 optimized 된 성능의 비교도 확인할 필요가 있다고 생각한다.

---

## Reference

- [Chen, Zhe, Jing Zhang, and Dacheng Tao. "Recurrent glimpse-based decoder for detection with transformer." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.html)
- [Carion, Nicolas, et al. "End-to-end object detection with transformers." European conference on computer vision. Springer, Cham, 2020.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjMmPaL3tz5AhVIQt4KHf0tBMUQFnoECAkQAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F2005.12872&usg=AOvVaw1fNz92-EEj1d91Nfiv875y)
- [Zhu, Xizhou, et al. "Deformable detr: Deformable transformers for end-to-end object detection." arXiv preprint arXiv:2010.04159 (2020).](https://arxiv.org/abs/2010.04159)